{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd370de3-c897-40bb-9753-bd985fbc2699",
   "metadata": {},
   "source": [
    "# DAA ML Intro - Activity 3\n",
    "\n",
    "This is a bit of a longer activity leveraging deep nerual networks for image classification. We pull data in using a slightly different method, but all the imports and downloading is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f842a34-2d4b-486a-bac3-b091741a6107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchsummary rich ipywidgets scikit_learn\n",
    "!wget https://github.com/YalinZhengLab/outreach/raw/main/test.zip\n",
    "!wget https://github.com/YalinZhengLab/outreach/raw/main/train.zip\n",
    "!mkdir data\n",
    "!unzip test.zip -d data/test/\n",
    "!unzip train.zip -d data/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afe0c8-c659-452a-a32f-93797f83e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries we need\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b357465-a021-4d5a-bff4-312fcb028d02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# What is AI, and how does it work?\n",
    "\n",
    "AI models are computer programs that aim to perform complex tasks to save us time and effort. Usually, this is about doing something that is time-consuming, and at a difficulty level which is too hard for simpler computer programs to solve. An easy example problem would be classifying images into \"Cats\" and \"Dogs\" - as humans we can do this very easily; but computers find this much harder (how does a computer know what a \"dog\" is?). By using AI, the computer \"learns\" the features of dogs and cats and can distinguish between the two.\n",
    "\n",
    "Automating these processes allows for us to spend our time doing more important things, instead of these tedious tasks. Perhaps more importantly, it allows us to do them on a scale that simply wouldn't be possible without AI (e.g. fraud detection for card transactions).\n",
    "\n",
    "Recently, most cutting-edge AI works using *neural networks*; these are massive mathematical models originally developed by neurologists to imitate how our brains worked. These models function by having millions, or billions of *parameters* that change as the model learns, improving the model as training continues.\n",
    "\n",
    "<img src=\"./img/nn.png\"/>\n",
    "\n",
    "In short, the way a model \"learns\" is by computing a *loss function* every so often in training; this is a general measure of how well the model is doing. The higher the loss, the worse the model performs, and the more the parameters change to try and fix it using some clever maths. All of this is handled by what we installed at the top of the page, but it's good to know how the model is working underneath the surface!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc122a3-39eb-4aca-ace2-76ade54b319b",
   "metadata": {},
   "source": [
    "# Training our own Neural Network\n",
    "\n",
    "We are going to build a model for detecting Glaucoma from fundus photography. This is a bit of a jump in difficulty but Python has several tools that will make it easier for us!\n",
    "\n",
    "Glaucoma is a common eye condition that is the leading cause of blindness in the UK. Clinicans will take a photo of the back of the eye and examine the images for features that are characteristic to the condition.\n",
    "\n",
    "![Example of a healthy retina](img/ex1.jpg)\n",
    "![Example of another healthy retina](img/ex2.jpg)\n",
    "\n",
    "We have an open-source dataset from the Rotterdam EyePACS AIROGS challenge (https://www.kaggle.com/datasets/deathtrooper/eyepacs-airogs-light?resource=download) that we are going to use to train our AI model. Under the `data/train` directory, we have 2500 positive (RG) and 2500 negative cases (NRG) of glaucoma.\n",
    "\n",
    "Our first job is to create Python object that contains all of our data ready to be trained; unfortunately the Python tool that manages the AI for us needs this code, and it's a bit abstract, so feel free to run it and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b166c-2e33-46bb-9a88-3ebe549ceb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to run this and ignore it. Classes are tricky!\n",
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, files):\n",
    "        # This function is run when creating a FundusDataset object\n",
    "        print(\"Fundus Dataset initialised!\")\n",
    "        self.files = files\n",
    "\n",
    "    def __len__(self):\n",
    "        # This function is called when using len() on the FundusDataset object\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # This function is called when using indexing (e.g. my_dataset[1]) on the dataset.\n",
    "        \n",
    "        image_path = self.files[idx]\n",
    "\n",
    "        # Read the file\n",
    "        image = read_image(image_path)\n",
    "\n",
    "        # Get the label\n",
    "        label = 0 if \"NRG\" in str(image_path) else 1\n",
    "\n",
    "        # return outputs the image, as well as the label for the model.\n",
    "        return image.float(), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7d962-4b49-43f9-860d-ee6a3adebc95",
   "metadata": {},
   "source": [
    "The code above doesn't actually do anything yet, it just sets up the next step.\n",
    "\n",
    "In the code below, we actually create an instance of the `FundusDataset` object we define above. Again, this needs a bit of setting up, but is a little more understandable.\n",
    "\n",
    "First, we need to get all the image files in the training folder. The `Path` type finds the training folder and gives us access to some helpful tools to work with files and folders. For example, `.glob()` finds files based on a pattern; `**` means \"any folder\" and `*` means \"any file\" - as long as it ends in .jpg! This will give us a list of all the fils in the training folder:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a308d-dca3-4456-9cce-6ca9534f931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(\"./data/train\").glob(\"**/*.jpg\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ceeb00-a154-457d-98f9-16d9bfa3344e",
   "metadata": {},
   "source": [
    "Now we have the list of all the training files, we can shuffle and take a subset of them for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6db79-c23f-40ed-b608-28f4cfc881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle this list to get a good mix of positive and negative eyes.\n",
    "random.shuffle(files)\n",
    "\n",
    "# 10k eyes is too much to work with now, so to speed things up we can take the first 1000\n",
    "# Note the colon in the index here - this is saying \"take every single element up to the 1000th\".\n",
    "files = files[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60699791-5808-4efb-9657-05b7b0becaae",
   "metadata": {},
   "source": [
    "Now we are ready to use the `FundusDataset` type we defined above to handle the data for our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50841cbd-4157-40c3-bce1-ce3bcd835097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created the FundusDataset object to convert this list\n",
    "# into a type of object PyTorch needs. It's fairly straightforward,\n",
    "# but the code is a bit challenging, so we've collapsed it above.\n",
    "training_dataset = FundusDataset(files)\n",
    "\n",
    "# Next, we convert this into a \"DataLoader\" - this prepares the \n",
    "# data ready to be put into the AI model!\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b2b37-56f4-4603-a237-060e87135dd4",
   "metadata": {},
   "source": [
    "The next thing we want to do is load and train the model. We are going to be doing this using the ResNet model (https://arxiv.org/abs/1512.03385), a well established, mature network that performs well on classification tasks.\n",
    "\n",
    "We do not need to know exactly how this AI works (although that's the excitement of AI research!), but we only need to know that we need to set up a few things for training to take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1015e1-e222-4a9c-ac07-9bae6dcb707a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can download the untrained model as follows.\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', num_classes=2, weights=None)\n",
    "\n",
    "# The loss function tells the model how well it's doing.\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# The optimizer will work to reduce the loss function by changing the model parameters\n",
    "# The amount the model parameters change depends on how bad the loss function is.\n",
    "# An important input here is \"lr\" - this is the learning rate of the model;\n",
    "# The higher the learning rate, the faster the model will train,\n",
    "# but increases training instability.\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "# This moves the model object to the right bit of memory. Safe to ignore this!\n",
    "model.to(device)\n",
    "\n",
    "# Finally, print a summary of the model. (3, 256, 256) means the model has size 256x256 and 3 channels:\n",
    "# red, green and blue.\n",
    "summary(model, input_size=(3,256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33985999-4d99-41aa-ae2c-85c0397e753a",
   "metadata": {},
   "source": [
    "And just like that, you have built a neural network with 12 million parameters ready to train!\n",
    "\n",
    "Now we can get to training our model; this is the part the computer does the most work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08734e-4ba5-456f-8228-63ea96bccfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A for loop tells Python to do something a number of times.\n",
    "# In this case, we are running through the entire dataset 10 times before stopping/\n",
    "# Try changing this 10 to a smaller number and see what happens!\n",
    "for epoch in range(20):\n",
    "\n",
    "    # This is a measure of how how well the model has done this epoch. Low is good!\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in track(training_dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move these to the right device. Safe to ignore this!\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients - this stops the model from making changes\n",
    "        # to the parameters based on old results\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get the model output for the input\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Mark how well the model has done\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Adjust the model parameters - if the model has done badly, adjust them a lot\n",
    "        # The parameters are adjusted in a way that should make the model a little better\n",
    "        # each time!\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the loss to the running loss - this is a measure of how well the model\n",
    "        # has done this epoch!\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch \n",
    "    print(epoch, \"loss\", running_loss / len(training_dataloader))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72556f2-2bdc-461a-a4ba-bd1378a8cfe5",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "Congratulations - you have just trained an AI model!\n",
    "\n",
    "Now that we have trained the model; we want to test how well the model is doing. When testing our models, it's unfair to use the data the model already has; we don't want to test the *memory* of the model, but the *understanding* of the model to look at the typical features of glaucoma. Typically, we split the dataset to reserve some images specifically for testing for this purpose - in fact, the `data` folder has a specific foldder for us here. All we need to do is set up the images in the same way as training and get the outputs.\n",
    "\n",
    "This is a key point for AI models; beyond the training dataset, they don't really know anything else. The model may be too specialised on the training dataset to perform well on data outside what it's seen before. However, if the model is not specialised enough, it may just not perform well on anything!\n",
    "\n",
    "From here, we can use some measures to see how well our model stacks up. We'll be using the `f1_score`, which is a fairly standard place to start for classification tasks, where a high F1 score is good. Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9b9e3-d07e-47c7-9413-0220bdd82930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process is very similar to the training process - we set up the dataset as before.\n",
    "files = list(Path(\"./data/test\").glob(\"**/*.jpg\"))\n",
    "random.shuffle(files)\n",
    "files = files[:100]\n",
    "testing_dataset = FundusDataset(files)\n",
    "testing_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Set up two lists \n",
    "truth = []\n",
    "predictions = []\n",
    "\n",
    "# The for loop now doesn't do something a number of times, but does something for\n",
    "# every element in a list - in this case, we are taking each image and it's label one by one\n",
    "# and comparing the model's prediction with what we know to be true.\n",
    "for data in track(testing_dataloader):\n",
    "    \n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "\n",
    "    # Getting the inputs to the right bit of computer memory\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Add the actual true labels to the truth list\n",
    "    truth.append(labels.numpy())\n",
    "\n",
    "    # Use the model to predict the diagnosis\n",
    "    outputs = model(inputs).detach().cpu().numpy().argmax(axis=1)\n",
    "\n",
    "    # Add this to the list\n",
    "    predictions.append(outputs)\n",
    "\n",
    "# Because of how the output comes out, we need the following code to \"flatten\" the lists\n",
    "# into one long array.\n",
    "truth = np.concatenate(truth)\n",
    "predictions = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e8bcd-9652-4df5-b6f4-234020d4b3df",
   "metadata": {},
   "source": [
    "We now have two lists - for every image in our testing dataset, we have the model prediction labels (1 for positive, 0 for negative), and the corresponding *true* values for each image. We can look at these by printing out the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c60a4-3780-4bf5-bec8-f68803f8748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truth)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f335b43-e88c-4fea-a90a-3b010a4b56a6",
   "metadata": {},
   "source": [
    "Clearly this isn't the best way to see how our model is doing - just looking at these numbers makes my eyes hurt! Let's look at the accuracy (how many it got right divided by the total number of images) and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c3e22-5492-48d7-b718-60bd5f14ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(truth, predictions)\n",
    "f1 = f1_score(truth, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
